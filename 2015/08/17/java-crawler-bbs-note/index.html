<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> Java爬虫爬取小百合BBS小记 · 坐在键盘上的猫</title><meta name="description" content="Java爬虫爬取小百合BBS小记 - John Doe"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="short icon" href="/favicon.ico"><link rel="stylesheet" href="/css/apollo.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,600" type="text/css"></head><body><header><a href="/" class="logo-link"><img src="/favicon.png"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="http://weibo.com/rdmclin2" target="_blank" class="nav-list-link">WEIBO</a></li><li class="nav-list-item"><a href="https://github.com/rdmclin2" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><section class="container"><div class="post"><article class="post-block"><h1 class="post-title">Java爬虫爬取小百合BBS小记</h1><div class="post-time">2015年8月17日</div><div class="post-content"><h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>本文关于<a href="http://bbs.nju.edu.cn" target="_blank" rel="external">小百合论坛</a>的爬取，共458个板块，每个板块1000个的帖子，主要借助开源包<a href="http://sourceforge.net/projects/htmlparser/files/Integration-Builds/2.0-20060923/" target="_blank" rel="external">htmlparser</a>,下面上分析过程和代码。注意本文在一篇<a href="http://www.ibm.com/developerworks/cn/opensource/os-cn-crawler/index.html" target="_blank" rel="external">ibm的文章</a>的基础上进行修改。</p>
<h2 id="更新"><a href="#更新" class="headerlink" title="更新"></a>更新</h2><p>我另外简单实现了一个MapReduce版本的，不过实现的不好，权当参考一下吧.奉上<a href="git@github.com:rdmclin2/MR_BBSCrawler.git">github地址</a>，上面有简单介绍.</p>
<a id="more"></a>
<hr>
<h1 id="分析过程及代码"><a href="#分析过程及代码" class="headerlink" title="分析过程及代码"></a>分析过程及代码</h1><h2 id="关于爬虫"><a href="#关于爬虫" class="headerlink" title="关于爬虫"></a>关于爬虫</h2><p>爬虫大家都知道，由一个种子页(seed)出发，分析该页，获取页面链接，加入未访问的列表中，从未访问的表中取链接，访问，重复如上步骤即可，要注意的就是要维护一个已访问的网页列表，以避免重复访问。然而这种广义的爬虫并不符合特定的情况，例如我现在要爬的bbs板块帖子，遇到具体问题，还是得具体分析。</p>
<hr>
<h2 id="小百合bbs爬取过程"><a href="#小百合bbs爬取过程" class="headerlink" title="小百合bbs爬取过程"></a>小百合bbs爬取过程</h2><p>基本的爬取步骤如下：</p>
<ul>
<li>首先获得小百合bbs的所有板块链接</li>
<li>对于每一个板块，获取至多1000条帖子的链接</li>
<li>对于每一条链接，获取帖子内容并存储</li>
</ul>
<hr>
<h3 id="获取所有板块链接"><a href="#获取所有板块链接" class="headerlink" title="获取所有板块链接"></a>获取所有板块链接</h3><p>那么，最好有个入口页面可以把所有板块的链接都收集好，直接爬就好，幸运的是小百合贴心的有个叫做<a href="http://bbs.nju.edu.cn/bbsall" target="_blank" rel="external">全部讨论区</a>的版面,lucky~省下不少功夫.<br>这一部分的代码如下(BoardParser.java):<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div></pre></td><td class="code"><pre><div class="line">package com.mcl.crawler;</div><div class="line"></div><div class="line">import java.util.HashSet;</div><div class="line">import java.util.Set;</div><div class="line"></div><div class="line">import org.htmlparser.Node;</div><div class="line">import org.htmlparser.Parser;</div><div class="line">import org.htmlparser.filters.NodeClassFilter;</div><div class="line">import org.htmlparser.tags.LinkTag;</div><div class="line">import org.htmlparser.util.NodeList;</div><div class="line">import org.htmlparser.util.ParserException;</div><div class="line"></div><div class="line">public class BoardParser &#123;</div><div class="line">	// 获取bbs网站上的所有板块链接</div><div class="line">	private Set&lt;String&gt; extracLinks(String url, LinkFilter filter) &#123;</div><div class="line"></div><div class="line">		Set&lt;String&gt; links = new HashSet&lt;String&gt;();</div><div class="line">		try &#123;</div><div class="line">			Parser parser = new Parser(url);</div><div class="line">			parser.setEncoding(&quot;UTF-8&quot;);</div><div class="line">			// linkFilter 来设置过滤 &lt;a&gt; 标签</div><div class="line">			NodeClassFilter linkFilter = new NodeClassFilter(LinkTag.class);</div><div class="line">			// 得到所有经过过滤的标签</div><div class="line">			NodeList list = parser.extractAllNodesThatMatch(linkFilter);</div><div class="line">			for (int i = 0; i &lt; list.size(); i++) &#123;</div><div class="line">				Node tag = list.elementAt(i);</div><div class="line">				if (tag instanceof LinkTag)// &lt;a&gt; 标签</div><div class="line">				&#123;</div><div class="line">					LinkTag link = (LinkTag) tag;</div><div class="line">					String linkUrl = link.getLink();// url</div><div class="line">					if (filter.accept(linkUrl)) &#123;</div><div class="line">						// 将一般模式切换成主题模式</div><div class="line">						String stlink = linkUrl.replace(&quot;bbsdoc&quot;, &quot;bbstdoc&quot;);</div><div class="line">						links.add(stlink);</div><div class="line">					&#125;</div><div class="line">				&#125;</div><div class="line">			&#125;</div><div class="line">		&#125; catch (ParserException e) &#123;</div><div class="line">			e.printStackTrace();</div><div class="line">		&#125;</div><div class="line">		return links;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	// 获取板块链接并切换成主题模式</div><div class="line">	public Set&lt;String&gt; getBoards(String seed) &#123;</div><div class="line">		Set&lt;String&gt; links = extracLinks(seed, new LinkFilter() &#123;</div><div class="line">			// 提取以 http://bbs.nju.edu.cn/bbsdoc 开头的链接</div><div class="line">			public boolean accept(String url) &#123;</div><div class="line">				if (url.startsWith(&quot;http://bbs.nju.edu.cn/bbsdoc&quot;))</div><div class="line">					return true;</div><div class="line">				else</div><div class="line">					return false;</div><div class="line">			&#125;</div><div class="line">		&#125;);</div><div class="line">		// System.out.println(links.size());</div><div class="line">		// for(String link : links)&#123;</div><div class="line">		// System.out.println(link);</div><div class="line">		// &#125;</div><div class="line">		return links;</div><div class="line">	&#125;</div><div class="line"></div><div class="line">	// 测试的 main 方法</div><div class="line">	// public static void main(String[]args)&#123;</div><div class="line">	// BoardParser.getBoards(&quot;http://bbs.nju.edu.cn/bbsall&quot;);</div><div class="line">	// &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<hr>
<h3 id="对于每一个板块，获取至多1000条帖子的链接"><a href="#对于每一个板块，获取至多1000条帖子的链接" class="headerlink" title="对于每一个板块，获取至多1000条帖子的链接"></a>对于每一个板块，获取至多1000条帖子的链接</h3><p>然后有了页面的链接，就要考虑怎么获取1000个帖子，我们并不想爬取回复，直接爬取主题，因此你可以看到上面将链接中的bbsdoc换成了bbstdoc，这就是主题模式。注意到bbs有个<code>上一页</code>的链接，那么获取这个链接，可以获得更多的帖子，不断反复，直到获取1000个帖子或没有更多的帖子.<br>以下是主要处理代码(FileParser.java):<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div></pre></td><td class="code"><pre><div class="line">package com.mcl.crawler;</div><div class="line"></div><div class="line">import java.util.HashMap;</div><div class="line">import java.util.Map;</div><div class="line">import java.util.Map.Entry;</div><div class="line"></div><div class="line">import org.htmlparser.Node;</div><div class="line">import org.htmlparser.Parser;</div><div class="line">import org.htmlparser.filters.NodeClassFilter;</div><div class="line">import org.htmlparser.tags.LinkTag;</div><div class="line">import org.htmlparser.util.NodeList;</div><div class="line">import org.htmlparser.util.ParserException;</div><div class="line"></div><div class="line">//获取bbs网站上某板块的所有帖子链接</div><div class="line">public class FileParser &#123;</div><div class="line">	//每个板块爬取1000个左右的帖子</div><div class="line">	private final int LINK_UP = 1000;</div><div class="line"></div><div class="line">	Map&lt;String,String&gt; links = new HashMap&lt;String,String&gt;();</div><div class="line">	private  String extracLinks(String url,LinkFilter filter) &#123;</div><div class="line">		//下一页的链接</div><div class="line">		String nextPage = null;</div><div class="line">		try &#123;</div><div class="line">			Parser parser = new Parser(url);</div><div class="line">			parser.setEncoding(&quot;gb2312&quot;);</div><div class="line">			// linkFilter 来设置过滤 &lt;a&gt; 标签</div><div class="line">			NodeClassFilter linkFilter = new NodeClassFilter(</div><div class="line">					LinkTag.class);</div><div class="line">			// 得到所有经过过滤的标签</div><div class="line">			NodeList list = parser.extractAllNodesThatMatch(linkFilter);</div><div class="line">			for (int i = 0; i &lt; list.size(); i++) &#123;</div><div class="line">				Node tag = list.elementAt(i);</div><div class="line">				if (tag instanceof LinkTag)// &lt;a&gt; 标签</div><div class="line">				&#123;</div><div class="line">					LinkTag link = (LinkTag) tag;</div><div class="line">					String linkUrl = link.getLink();// url</div><div class="line"></div><div class="line">					//获取上一页的链接，作为下一步的链接</div><div class="line">					if(link.getLinkText().equals(&quot;上一页&quot;))&#123;</div><div class="line">						nextPage = linkUrl;</div><div class="line">					&#125;</div><div class="line"></div><div class="line">					if(filter.accept(linkUrl) &amp;&amp; links.size() &lt; LINK_UP)&#123;</div><div class="line">						String title = link.getLinkText();</div><div class="line">						links.put(linkUrl, title);</div><div class="line">					&#125;</div><div class="line">				&#125;</div><div class="line">			&#125;</div><div class="line">		&#125; catch (ParserException e) &#123;</div><div class="line">			e.printStackTrace();</div><div class="line">		&#125;</div><div class="line">		return nextPage;</div><div class="line">	&#125;</div><div class="line"></div><div class="line"></div><div class="line">		//获取板块链接并切换成主题模式</div><div class="line">		public  Map&lt;String, String&gt; getFileUrls(String seed)</div><div class="line">		&#123;</div><div class="line">			System.out.println(&quot;seed: &quot;+ seed);</div><div class="line">			links.clear();</div><div class="line">			int linkCount = 0;</div><div class="line">			final String rule = seed.replace(&quot;bbstdoc&quot;, &quot;bbstcon&quot;);</div><div class="line">			String list = seed;</div><div class="line">			while(linkCount &lt; LINK_UP)&#123;</div><div class="line">				list = extracLinks(list,new LinkFilter()</div><div class="line">				&#123;</div><div class="line">					//提取以 http://bbs.nju.edu.cn/bbstcon?board=... 开头的链接</div><div class="line">					public boolean accept(String url) &#123;</div><div class="line">						if(url.startsWith(rule))</div><div class="line">							return true;</div><div class="line">						else</div><div class="line">							return false;</div><div class="line">					&#125;</div><div class="line">				&#125;);</div><div class="line">				linkCount = links.size();</div><div class="line">				//如果没有下一页的链接了</div><div class="line">				if(list == null)&#123;</div><div class="line">					break;</div><div class="line">				&#125;</div><div class="line">				try &#123;</div><div class="line">					Thread.sleep(360);</div><div class="line">				&#125; catch (InterruptedException e) &#123;</div><div class="line">					// TODO Auto-generated catch block</div><div class="line">					e.printStackTrace();</div><div class="line">				&#125;</div><div class="line">			&#125;</div><div class="line">			System.out.println(&quot;共 &quot;+ links.size()+&quot; 篇帖子&quot;);</div><div class="line">			for (Entry&lt;String, String&gt; entry : links.entrySet()) &#123;</div><div class="line">				System.out.println(entry.getKey()+&quot; &quot;+entry.getValue());</div><div class="line">			&#125;</div><div class="line">			return links;</div><div class="line">		&#125;</div><div class="line"></div><div class="line">		//测试的 main 方法</div><div class="line">		public static void main(String[]args)&#123;</div><div class="line">			FileParser parser = new FileParser();</div><div class="line">			parser.getFileUrls(&quot;http://bbs.nju.edu.cn/bbstdoc?board=Blog&quot;);</div><div class="line">		&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<hr>
<h3 id="对于每一条链接，获取帖子内容并存储"><a href="#对于每一条链接，获取帖子内容并存储" class="headerlink" title="对于每一条链接，获取帖子内容并存储"></a>对于每一条链接，获取帖子内容并存储</h3><p>得到帖子的链接，下面就是获取帖子的内容,我们获取table-&gt;tbody-&gt;第二个tr-&gt;td-&gt;pre中的纯文本。<br>代码如下(FileDownLoader):<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div></pre></td><td class="code"><pre><div class="line">package com.mcl.crawler;</div><div class="line"></div><div class="line">import java.io.BufferedWriter;</div><div class="line">import java.io.File;</div><div class="line">import java.io.FileOutputStream;</div><div class="line">import java.io.IOException;</div><div class="line">import java.io.OutputStreamWriter;</div><div class="line"></div><div class="line">import org.htmlparser.NodeFilter;</div><div class="line">import org.htmlparser.Parser;</div><div class="line">import org.htmlparser.filters.AndFilter;</div><div class="line">import org.htmlparser.filters.HasAttributeFilter;</div><div class="line">import org.htmlparser.filters.NodeClassFilter;</div><div class="line">import org.htmlparser.filters.TagNameFilter;</div><div class="line">import org.htmlparser.tags.TableTag;</div><div class="line">import org.htmlparser.util.NodeList;</div><div class="line">import org.htmlparser.util.ParserException;</div><div class="line"></div><div class="line">public class FileDownLoader &#123;</div><div class="line">public static boolean createFile(String destFileName) &#123;  </div><div class="line">      File file = new File(destFileName);  </div><div class="line">      if(file.exists()) &#123;  </div><div class="line">          System.out.println(&quot;创建单个文件&quot; + destFileName + &quot;失败，目标文件已存在！&quot;);</div><div class="line">          return false;  </div><div class="line">      &#125;  </div><div class="line">      if (destFileName.endsWith(File.separator)) &#123;  </div><div class="line">          System.out.println(&quot;创建单个文件&quot; + destFileName + &quot;失败，目标文件不能为目录！&quot;);  </div><div class="line">          return false;  </div><div class="line">      &#125;  </div><div class="line">      //判断目标文件所在的目录是否存在  </div><div class="line">      if(!file.getParentFile().exists()) &#123;  </div><div class="line">          //如果目标文件所在的目录不存在，则创建父目录  </div><div class="line">          //System.out.println(&quot;目标文件所在目录不存在，准备创建它！&quot;);  </div><div class="line">          if(!file.getParentFile().mkdirs()) &#123;  </div><div class="line">              System.out.println(&quot;创建目标文件所在目录失败！&quot;);  </div><div class="line">              return false;  </div><div class="line">          &#125;  </div><div class="line">      &#125;  </div><div class="line">      //创建目标文件  </div><div class="line">      try &#123;  </div><div class="line">          if (file.createNewFile()) &#123;  </div><div class="line">              return true;  </div><div class="line">          &#125; else &#123;  </div><div class="line">              return false;  </div><div class="line">          &#125;  </div><div class="line">      &#125; catch (IOException e) &#123;  </div><div class="line">          e.printStackTrace();  </div><div class="line">          System.out.println(&quot;创建单个文件&quot; + destFileName + &quot;失败！&quot; + e.getMessage());  </div><div class="line">          return false;  </div><div class="line">      &#125;  </div><div class="line">  &#125;</div><div class="line"></div><div class="line"></div><div class="line">/**保存网页字节数组到本地文件</div><div class="line"> * filePath 为要保存的文件的相对地址</div><div class="line"> */</div><div class="line"> private void saveToLocal(String content,String filePath)</div><div class="line"> &#123;</div><div class="line">   try &#123;</div><div class="line">     createFile(filePath);</div><div class="line">     OutputStreamWriter osw;</div><div class="line">     String encoding = &quot;UTF-8&quot;;</div><div class="line">     osw = new OutputStreamWriter(</div><div class="line">         new FileOutputStream(filePath), encoding);</div><div class="line">     BufferedWriter bw = new BufferedWriter(osw);</div><div class="line">     bw.write(content);</div><div class="line"></div><div class="line">     bw.close();</div><div class="line">     osw.close();</div><div class="line">   &#125; catch (IOException e) &#123;</div><div class="line">     e.printStackTrace();</div><div class="line">   &#125;</div><div class="line"> &#125;</div><div class="line"></div><div class="line">/*下载 url 指向的网页的帖子内容并存储*/</div><div class="line">public String  downloadFile(String url,String filePath)</div><div class="line">&#123;</div><div class="line">  System.out.println(&quot;filePath: &quot;+filePath);</div><div class="line">  Parser parser;</div><div class="line">  try &#123;</div><div class="line">    parser = new Parser(url);</div><div class="line">    parser.setEncoding(&quot;UTF-8&quot;);</div><div class="line">    NodeList tableOfPre1 = parser.extractAllNodesThatMatch(</div><div class="line">          (NodeFilter) new AndFilter(new NodeClassFilter(TableTag.class), new HasAttributeFilter(&quot;class&quot;, &quot;main&quot;)));</div><div class="line">      if(tableOfPre1 != null &amp;&amp; tableOfPre1.size() &gt; 0) &#123;</div><div class="line">         // 获取指定 table 标签的子节点中的 &lt;tbody&gt; 节点</div><div class="line">         NodeList tList = tableOfPre1.elementAt(0).getChildren().extractAllNodesThatMatch (new TagNameFilter(&quot;tr&quot;), true);</div><div class="line">         //第二列第一个tag：pre</div><div class="line">         String text = tList.elementAt(1).getFirstChild().toPlainTextString();</div><div class="line">         //System.out.println(text);</div><div class="line">         saveToLocal(text,filePath);</div><div class="line"></div><div class="line">      &#125;</div><div class="line">    &#125; catch (ParserException e) &#123;</div><div class="line">      e.printStackTrace();</div><div class="line">    &#125;</div><div class="line">  return null;</div><div class="line">&#125;</div><div class="line">//测试的 main 方法</div><div class="line">public static void main(String[]args)</div><div class="line">&#123;</div><div class="line">  FileDownLoader downLoader = new FileDownLoader();</div><div class="line">  downLoader.downloadFile(&quot;http://bbs.nju.edu.cn/bbstcon?board=Blog&amp;file=M.1373384270.A&quot;,&quot;temp/Blog/我私人区最后一篇文章自动消失了，能找回吗？.txt&quot;);</div><div class="line">&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<hr>
<h3 id="main文件"><a href="#main文件" class="headerlink" title="main文件"></a>main文件</h3><p>最后把这些步骤串起来,分为3层进行处理,因为帖子名称可能重复，因此在生成的文件名中加入帖子的id以保证唯一性,最后因为小百合连续获取帖子会出错，因此我们间隔一段时间获取数据，这个时间需要自己测试.<br>主要代码如下(Crawler.java)：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div></pre></td><td class="code"><pre><div class="line">package com.mcl.crawler;</div><div class="line"></div><div class="line">import java.util.Dictionary;</div><div class="line">import java.util.Map;</div><div class="line">import java.util.Set;</div><div class="line">import java.util.Map.Entry;</div><div class="line">public class Crawler &#123;</div><div class="line">	private final String dir = &quot;temp&quot;;</div><div class="line">	/* 爬取方法*/</div><div class="line">	public void crawling(String seed)</div><div class="line">	&#123;</div><div class="line">		FileParser fileParser = new FileParser();</div><div class="line">		BoardParser boardParser = new BoardParser();</div><div class="line">		FileDownLoader downLoader=new FileDownLoader();</div><div class="line"></div><div class="line">		//第一层获取所有板块帖子</div><div class="line">		Set&lt;String&gt; boardsSet = boardParser.getBoards(seed);</div><div class="line">		for (String visitUrl : boardsSet) &#123;</div><div class="line">			String board = visitUrl.trim().split(&quot;=&quot;)[1];</div><div class="line"></div><div class="line">			try &#123;</div><div class="line">				Thread.sleep(500);</div><div class="line">			&#125; catch (InterruptedException e) &#123;</div><div class="line">				// TODO Auto-generated catch block</div><div class="line">				e.printStackTrace();</div><div class="line">			&#125;</div><div class="line">			Map&lt;String, String&gt; fileMap = fileParser.getFileUrls(visitUrl);</div><div class="line">			//第三层，下载每个帖子的内容</div><div class="line">			for (Entry&lt;String, String&gt; entry : fileMap.entrySet()) &#123;</div><div class="line">				String id = entry.getKey().split(&quot;=&quot;)[2];</div><div class="line">				String path = dir+&quot;/&quot;+board+&quot;/&quot;+entry.getValue().trim()+&quot;_&quot;+id+&quot;.txt&quot;;</div><div class="line">				downLoader.downloadFile(entry.getKey(),path);</div><div class="line">				try &#123;</div><div class="line">					Thread.sleep(500);</div><div class="line">				&#125; catch (InterruptedException e) &#123;</div><div class="line">					// TODO Auto-generated catch block</div><div class="line">					e.printStackTrace();</div><div class="line">				&#125;</div><div class="line">			&#125;</div><div class="line">		&#125;</div><div class="line">	&#125;</div><div class="line">	//main 方法入口</div><div class="line">	public static void main(String[]args)</div><div class="line">	&#123;</div><div class="line">		Crawler crawler = new Crawler();</div><div class="line">		crawler.crawling(&quot;http://bbs.nju.edu.cn/bbsall&quot;);</div><div class="line">	&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<hr>
<h2 id="代码上传到github"><a href="#代码上传到github" class="headerlink" title="代码上传到github"></a>代码上传到github</h2><p>最后，因为htmlparser还会依赖一些其他的包，为了方便起见，已把代码发到<a href="https://github.com/rdmclin2/BBSCrawler" target="_blank" rel="external">github</a>上,希望能够帮到你。</p>
<hr>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul>
<li><a href="http://www.oschina.net/code/snippet_246199_9298" target="_blank" rel="external">htmlparser提取新闻</a></li>
<li><a href="http://gcgmh.iteye.com/blog/442560" target="_blank" rel="external">htmlparser精确提取</a></li>
<li><a href="http://www.ibm.com/developerworks/cn/opensource/os-cn-crawler/index.html" target="_blank" rel="external">使用 HttpClient 和 HtmlParser 实现简易爬虫</a></li>
</ul>
</div></article></div></section><footer><div class="paginator"><a href="/2015/08/19/html-note/" class="prev">上一篇</a><a href="/2015/08/10/github-pages-create-custrom-website/" class="next">下一篇</a></div><div id="disqus_thread"></div><script>var disqus_shortname = 'mcl';
var disqus_identifier = '2015/08/17/java-crawler-bbs-note/';
var disqus_title = 'Java爬虫爬取小百合BBS小记';
var disqus_url = 'http://www.mclspace.com/2015/08/17/java-crawler-bbs-note/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//mcl.disqus.com/count.js" async></script><div class="copyright"><p>© 2015 - 2017 <a href="http://www.mclspace.com">John Doe</a>, unless otherwise noted.</p></div></footer><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "//hm.baidu.com/hm.js?6b26d13232555e4d64b5a8c3567ccda9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script src="https://cdn.bootcss.com/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>
<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> Mac上Hadoop的安装及使用 · 坐在键盘上的猫</title><meta name="description" content="Mac上Hadoop的安装及使用 - John Doe"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="short icon" href="/favicon.ico"><link rel="stylesheet" href="/css/apollo.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,600" type="text/css"></head><body><header><a href="/" class="logo-link"><img src="/favicon.png"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="http://weibo.com/rdmclin2" target="_blank" class="nav-list-link">WEIBO</a></li><li class="nav-list-item"><a href="https://github.com/rdmclin2" target="_blank" class="nav-list-link">GITHUB</a></li><li class="nav-list-item"><a href="/atom.xml" target="_self" class="nav-list-link">RSS</a></li></ul></header><section class="container"><div class="post"><article class="post-block"><h1 class="post-title">Mac上Hadoop的安装及使用</h1><div class="post-time">2015年9月1日</div><div class="post-content"><blockquote>
<p>本文在mac osx 上安装配置hadoop环境,配置eclipse开发环境，并打包jar文件在集群上运行.</p>
</blockquote>
<a id="more"></a>
<h2 id="Mac安装hadoop环境"><a href="#Mac安装hadoop环境" class="headerlink" title="Mac安装hadoop环境"></a><code>Mac安装hadoop环境</code></h2><p>参考 <a href="http://andrewliu.in/2015/03/05/%E5%9C%A8Mac-OSX-Yosemite%E4%B8%8A%E5%AE%89%E8%A3%85Hadoop/" target="_blank" rel="external">在Mac OSX Yosemite上安装Hadoop</a></p>
<h3 id="设置alias"><a href="#设置alias" class="headerlink" title="设置alias"></a>设置alias</h3><p>在zsh的.zshrc中配置打开和关闭hadoop的alias<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">alias hstart=&quot;/usr/local/Cellar/hadoop/2.7.1/sbin/start-dfs.sh;/usr/local/Cellar/hadoop/2.7.1/sbin/start-yarn.sh&quot;</div><div class="line">alias hstop=&quot;/usr/local/Cellar/hadoop/2.7.1/sbin/stop-yarn.sh;/usr/local/Cellar/hadoop/2.7.1/sbin/stop-dfs.sh&quot;</div></pre></td></tr></table></figure></p>
<p>然后还有hbase的<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">alias hbstart=&quot;/usr/local/Cellar/hbase/1.0.1/libexec/bin/start-hbase.sh&quot;</div><div class="line">alias hbstop=&quot;/usr/local/Cellar/hbase/1.0.1/libexec/bin/stop-hbase.sh&quot;</div></pre></td></tr></table></figure></p>
<h3 id="开启成功的标识"><a href="#开启成功的标识" class="headerlink" title="开启成功的标识"></a>开启成功的标识</h3><p>使用<code>jps</code>命令，出现以下几项:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">2821 ResourceManager</div><div class="line">2582 DataNode</div><div class="line">2918 NodeManager</div><div class="line">2968 Jps</div><div class="line">2699 SecondaryNameNode</div><div class="line">2493 NameNode</div></pre></td></tr></table></figure></p>
<p>使用如下命令测试是否能够正确执行hadoop程序:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hadoop jar /usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar pi 2 5</div></pre></td></tr></table></figure></p>
<h3 id="查看web任务的接口"><a href="#查看web任务的接口" class="headerlink" title="查看web任务的接口"></a>查看web任务的接口</h3><p>我们可以通过以下web接口查看mapreduce任务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">http://localhost:8088 Cluster Status 这个接口非常有用,2.2之后,之前用50030端口</div><div class="line">http://localhost:50070/ HDFS status</div><div class="line">http://localhost:50090 secondaryNamenode</div></pre></td></tr></table></figure></p>
<hr>
<p><br></p>
<h2 id="安装配置eclipse插件"><a href="#安装配置eclipse插件" class="headerlink" title="安装配置eclipse插件"></a><code>安装配置eclipse插件</code></h2><h3 id="下载地址-2-7-0"><a href="#下载地址-2-7-0" class="headerlink" title="下载地址(2.7.0)"></a>下载地址(2.7.0)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">http://download.csdn.net/detail/yew1eb/8716117</div></pre></td></tr></table></figure>
<h3 id="插件设置"><a href="#插件设置" class="headerlink" title="插件设置"></a>插件设置</h3><p>在偏好设置 -&gt; Hadoop Map/Reduce中配置Hadoop installation directory为:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">/usr/local/Cellar/hadoop/2.7.1/libexec</div><div class="line">#因人而异,这里是用homebrew安装hadoop后的地址</div></pre></td></tr></table></figure></p>
<h3 id="打开mapreduce工作空间"><a href="#打开mapreduce工作空间" class="headerlink" title="打开mapreduce工作空间"></a>打开mapreduce工作空间</h3><p>Window -&gt; Open Perspective -&gt; Other -&gt; Map/Reduce</p>
<h3 id="添加hadoop地址"><a href="#添加hadoop地址" class="headerlink" title="添加hadoop地址"></a>添加hadoop地址</h3><p>在下面状态栏的Map/Reduce Locations中右击,选择New Hadoop location<br>配置 ：</p>
<ul>
<li>Location name : 随意,如<code>hadoop</code></li>
<li><p>Map/Reduce Master的端口参考</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/usr/local/Cellar/hadoop/2.7.1/libexec/etc/hadoop/mapred-site.xml</div></pre></td></tr></table></figure>
</li>
<li><p>DFS Master的端口参考</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/usr/local/Cellar/hadoop/2.7.1/libexec/etc/hadoop/core-site.xml</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="配置完成标志"><a href="#配置完成标志" class="headerlink" title="配置完成标志"></a>配置完成标志</h3><p>点击左侧的DFSLocations—&gt;hadoop（上一步配置的location name)，如能看到user，表示安装成功（保证已经启动了hadoop)</p>
<hr>
<p><br></p>
<h2 id="实战程序wordcount"><a href="#实战程序wordcount" class="headerlink" title="实战程序wordcount"></a><code>实战程序wordcount</code></h2><h3 id="新建WordCount项目"><a href="#新建WordCount项目" class="headerlink" title="新建WordCount项目"></a>新建WordCount项目</h3><p>File—&gt;Project，选择Map/Reduce Project，输入项目名称WordCount等。</p>
<p>在WordCount项目里新建class，名称为WordCount，代码如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div></pre></td><td class="code"><pre><div class="line">import java.io.IOException;</div><div class="line">import java.util.StringTokenizer;</div><div class="line"></div><div class="line">import org.apache.hadoop.conf.Configuration;</div><div class="line">import org.apache.hadoop.fs.Path;</div><div class="line">import org.apache.hadoop.io.IntWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Job;</div><div class="line">import org.apache.hadoop.mapreduce.Mapper;</div><div class="line">import org.apache.hadoop.mapreduce.Reducer;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line">import org.apache.hadoop.util.GenericOptionsParser;</div><div class="line"></div><div class="line">public class WordCount &#123;</div><div class="line"></div><div class="line">public static class TokenizerMapper extends Mapper&lt;Object, Text, Text, IntWritable&gt;&#123;</div><div class="line">　　private final static IntWritable one = new IntWritable(1);</div><div class="line">　　private Text word = new Text();</div><div class="line"></div><div class="line">　　public void map(Object key, Text value, Context context) throws IOException, InterruptedException &#123;</div><div class="line">　　　　StringTokenizer itr = new StringTokenizer(value.toString());</div><div class="line">　　　　　　while (itr.hasMoreTokens()) &#123;</div><div class="line">　　　　　　　　word.set(itr.nextToken());</div><div class="line">　　　　　　　　context.write(word, one);</div><div class="line">　　　　　　&#125;</div><div class="line">　　&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">public static class IntSumReducer extends Reducer&lt;Text,IntWritable,Text,IntWritable&gt; &#123;</div><div class="line">　　private IntWritable result = new IntWritable();</div><div class="line">　　public void reduce(Text key, Iterable&lt;IntWritable&gt; values,Context context) throws IOException, InterruptedException &#123;</div><div class="line">　　　　int sum = 0;</div><div class="line">　　　　for (IntWritable val : values) &#123;</div><div class="line">　　　　　　sum += val.get();</div><div class="line">　　　　&#125;</div><div class="line">　　　　result.set(sum);</div><div class="line">　　　　context.write(key, result);</div><div class="line">　　&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">public static void main(String[] args) throws Exception &#123;</div><div class="line">　　Configuration conf = new Configuration();</div><div class="line">　　String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();</div><div class="line">　　if (otherArgs.length != 2) &#123;</div><div class="line">　　　　System.err.println(&quot;Usage: wordcount &lt;in&gt; &lt;out&gt;&quot;);</div><div class="line">　　　　System.exit(2);</div><div class="line">　　&#125;</div><div class="line">　　Job job = new Job(conf, &quot;word count&quot;);</div><div class="line">　　job.setJarByClass(WordCount.class);</div><div class="line">　　job.setMapperClass(TokenizerMapper.class);</div><div class="line">　　job.setCombinerClass(IntSumReducer.class);</div><div class="line">　　job.setReducerClass(IntSumReducer.class);</div><div class="line">　　job.setOutputKeyClass(Text.class);</div><div class="line">　　job.setOutputValueClass(IntWritable.class);</div><div class="line">　　FileInputFormat.addInputPath(job, new Path(otherArgs[0]));</div><div class="line">　　FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]));</div><div class="line">　　System.exit(job.waitForCompletion(true) ? 0 : 1);</div><div class="line">&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="创建输入input目录"><a href="#创建输入input目录" class="headerlink" title="创建输入input目录"></a>创建输入input目录</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hadoop fs -mkdir /user</div><div class="line">hadoop fs -mkdir /user/input</div></pre></td></tr></table></figure>
<h3 id="拷贝本地README-txt到HDFS的input里"><a href="#拷贝本地README-txt到HDFS的input里" class="headerlink" title="拷贝本地README.txt到HDFS的input里"></a>拷贝本地README.txt到HDFS的input里</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hadoop fs -copyFromLocal /opt/hadoop/README.txt /user/input</div></pre></td></tr></table></figure>
<h3 id="参数配置"><a href="#参数配置" class="headerlink" title="参数配置"></a>参数配置</h3><p>点击WordCount.java，右键，点击Run As—&gt;Run Configurations，配置运行参数Arguments，即输入和输出文件夹(事先不能存在)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">　　hdfs://localhost:9000/user/input    hdfs://localhost:9000/user/output</div></pre></td></tr></table></figure></p>
<p>然后点击运行</p>
<h3 id="查看结果"><a href="#查看结果" class="headerlink" title="查看结果"></a>查看结果</h3><p><code>hadoop fs -ls output</code>,可以看到有两个输出结果<code>_SUCCESS</code>和<code>part-r-00000</code><br>执行<code>hadoop fs -cat output/*</code></p>
<p>或者也可以展开DFS Locations，双击打开part-r00000查看结果</p>
<hr>
<p><br></p>
<h2 id="打包eclipse程序在集群上运行"><a href="#打包eclipse程序在集群上运行" class="headerlink" title="打包eclipse程序在集群上运行"></a><code>打包eclipse程序在集群上运行</code></h2><p>直接运行eclipse程序，访问localhost:8088窗口并不会显示正在运行的job，因为在eclipse上并没有配置集群环境，而是本地环境。</p>
<h3 id="打包jar"><a href="#打包jar" class="headerlink" title="打包jar"></a>打包jar</h3><p>右击工程 -&gt; export… -&gt; java -&gt; jar file -&gt; next -&gt; 填写jar包位置 -&gt; finish</p>
<h3 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hadoop jar crawler.jar MR_Crawler hdfs://localhost:9000/user/input/urls hdfs://localhost:9000/user/output</div><div class="line"># 注意用MR_Crawler是因为没有配置具体的package，如果有包要加上包名.</div></pre></td></tr></table></figure>
<hr>
<p><br></p>
<h2 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a><code>注意点</code></h2><ul>
<li>运行后台程序前, 必须格式化新安装的HDFS, 并通过创建存储目录和初始化元数据创新空的文件系统, 执行下面命令<code>hdfs namenode -format</code></li>
<li>输出文件默认不能存在</li>
</ul>
</div></article></div></section><footer><div class="paginator"><a href="/2015/09/16/docker-file-note/" class="prev">PRVE</a><a href="/2015/08/22/docker-create-nodejs-mongodb-image/" class="next">NEXT</a></div><div id="disqus_thread"></div><script>var disqus_shortname = 'mcl';
var disqus_identifier = '2015/09/01/hadoop-note/';
var disqus_title = 'Mac上Hadoop的安装及使用';
var disqus_url = 'http://www.mclspace.com/2015/09/01/hadoop-note/';
(function() {
    var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
})();</script><script id="dsq-count-scr" src="//mcl.disqus.com/count.js" async></script><div class="copyright"><p>© 2015 - 2017 <a href="http://www.mclspace.com">John Doe</a>, unless otherwise noted.</p></div></footer><script>var _hmt = _hmt || [];(function() {var hm = document.createElement("script");hm.src = "//hm.baidu.com/hm.js?6b26d13232555e4d64b5a8c3567ccda9";var s = document.getElementsByTagName("script")[0]; s.parentNode.insertBefore(hm, s);})();</script><script src="https://cdn.bootcss.com/mathjax/2.5.3/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>
<!DOCTYPE html><html lang="zh-CN"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="大猫Calvin"><title>Mac上Hadoop的安装及使用 · 坐在键盘上的猫</title><meta name="description" content="本文在mac osx 上安装配置hadoop环境,配置eclipse开发环境，并打包jar文件在集群上运行.


Mac安装hadoop环境参考 在Mac OSX Yosemite上安装Hadoop
设置alias在zsh的.zshrc中配置打开和关闭hadoop的alias12alias hsta"><meta name="keywords" content="front end, nodejs, html,css,js,android,java"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="short icon" href="/images/favicon.png" type="image/x-icon"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"></head><body><div class="sidebar animated fadeInDown"><div class="logo-title"><div class="title"><img src="/images/logo@2x.png" style="width:127px;"><h3 title=""><a href="/">坐在键盘上的猫</a></h3><div class="description"><p>站在艺术与技术交汇之处</p></div></div></div><ul class="social-links"><li><a href="/atom.xml"><i class="fa fa-rss"></i></a></li><li><a href="http://weibo.com/rdmclin2"><i class="fa fa-weibo"></i></a></li></ul><div class="footer"><a target="_blank" href="/"><span>Theme by </span></a><a href="https://www.caicai.me"> CaiCai</a><span>&</span><a href="https://github.com/Ben02/hexo-theme-Anatole"> Ben</a><div class="by_farbox"><a href="https://hexo.io/zh-cn/" target="_blank">Proudly published with Hexo&#65281;</a></div></div></div><div class="main"><div class="page-top animated fadeInDown"><div class="nav"><li><a href="/">首页</a></li><li><a href="/about">关于</a></li><li><a href="/archives">归档</a></li><li><a href="/links">友链</a></li></div><div class="information"><div class="back_btn"><li><a onclick="window.history.go(-1)" class="fa fa-chevron-left"> </a></li></div><div class="avatar"><img src="https://avatars2.githubusercontent.com/u/4705237?v=3&amp;s=460"></div></div></div><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>Mac上Hadoop的安装及使用</a></h3></div><div class="post-content"><blockquote>
<p>本文在mac osx 上安装配置hadoop环境,配置eclipse开发环境，并打包jar文件在集群上运行.</p>
</blockquote>
<a id="more"></a>
<h2 id="Mac安装hadoop环境"><a href="#Mac安装hadoop环境" class="headerlink" title="Mac安装hadoop环境"></a><code>Mac安装hadoop环境</code></h2><p>参考 <a href="http://andrewliu.in/2015/03/05/%E5%9C%A8Mac-OSX-Yosemite%E4%B8%8A%E5%AE%89%E8%A3%85Hadoop/" target="_blank" rel="external">在Mac OSX Yosemite上安装Hadoop</a></p>
<h3 id="设置alias"><a href="#设置alias" class="headerlink" title="设置alias"></a>设置alias</h3><p>在zsh的.zshrc中配置打开和关闭hadoop的alias<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">alias hstart=&quot;/usr/local/Cellar/hadoop/2.7.1/sbin/start-dfs.sh;/usr/local/Cellar/hadoop/2.7.1/sbin/start-yarn.sh&quot;</div><div class="line">alias hstop=&quot;/usr/local/Cellar/hadoop/2.7.1/sbin/stop-yarn.sh;/usr/local/Cellar/hadoop/2.7.1/sbin/stop-dfs.sh&quot;</div></pre></td></tr></table></figure></p>
<p>然后还有hbase的<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">alias hbstart=&quot;/usr/local/Cellar/hbase/1.0.1/libexec/bin/start-hbase.sh&quot;</div><div class="line">alias hbstop=&quot;/usr/local/Cellar/hbase/1.0.1/libexec/bin/stop-hbase.sh&quot;</div></pre></td></tr></table></figure></p>
<h3 id="开启成功的标识"><a href="#开启成功的标识" class="headerlink" title="开启成功的标识"></a>开启成功的标识</h3><p>使用<code>jps</code>命令，出现以下几项:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">2821 ResourceManager</div><div class="line">2582 DataNode</div><div class="line">2918 NodeManager</div><div class="line">2968 Jps</div><div class="line">2699 SecondaryNameNode</div><div class="line">2493 NameNode</div></pre></td></tr></table></figure></p>
<p>使用如下命令测试是否能够正确执行hadoop程序:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hadoop jar /usr/local/Cellar/hadoop/2.7.1/libexec/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar pi 2 5</div></pre></td></tr></table></figure></p>
<h3 id="查看web任务的接口"><a href="#查看web任务的接口" class="headerlink" title="查看web任务的接口"></a>查看web任务的接口</h3><p>我们可以通过以下web接口查看mapreduce任务<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">http://localhost:8088 Cluster Status 这个接口非常有用,2.2之后,之前用50030端口</div><div class="line">http://localhost:50070/ HDFS status</div><div class="line">http://localhost:50090 secondaryNamenode</div></pre></td></tr></table></figure></p>
<hr>
<p><br></p>
<h2 id="安装配置eclipse插件"><a href="#安装配置eclipse插件" class="headerlink" title="安装配置eclipse插件"></a><code>安装配置eclipse插件</code></h2><h3 id="下载地址-2-7-0"><a href="#下载地址-2-7-0" class="headerlink" title="下载地址(2.7.0)"></a>下载地址(2.7.0)</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">http://download.csdn.net/detail/yew1eb/8716117</div></pre></td></tr></table></figure>
<h3 id="插件设置"><a href="#插件设置" class="headerlink" title="插件设置"></a>插件设置</h3><p>在偏好设置 -&gt; Hadoop Map/Reduce中配置Hadoop installation directory为:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">/usr/local/Cellar/hadoop/2.7.1/libexec</div><div class="line">#因人而异,这里是用homebrew安装hadoop后的地址</div></pre></td></tr></table></figure></p>
<h3 id="打开mapreduce工作空间"><a href="#打开mapreduce工作空间" class="headerlink" title="打开mapreduce工作空间"></a>打开mapreduce工作空间</h3><p>Window -&gt; Open Perspective -&gt; Other -&gt; Map/Reduce</p>
<h3 id="添加hadoop地址"><a href="#添加hadoop地址" class="headerlink" title="添加hadoop地址"></a>添加hadoop地址</h3><p>在下面状态栏的Map/Reduce Locations中右击,选择New Hadoop location<br>配置 ：</p>
<ul>
<li>Location name : 随意,如<code>hadoop</code></li>
<li><p>Map/Reduce Master的端口参考</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/usr/local/Cellar/hadoop/2.7.1/libexec/etc/hadoop/mapred-site.xml</div></pre></td></tr></table></figure>
</li>
<li><p>DFS Master的端口参考</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">/usr/local/Cellar/hadoop/2.7.1/libexec/etc/hadoop/core-site.xml</div></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="配置完成标志"><a href="#配置完成标志" class="headerlink" title="配置完成标志"></a>配置完成标志</h3><p>点击左侧的DFSLocations—&gt;hadoop（上一步配置的location name)，如能看到user，表示安装成功（保证已经启动了hadoop)</p>
<hr>
<p><br></p>
<h2 id="实战程序wordcount"><a href="#实战程序wordcount" class="headerlink" title="实战程序wordcount"></a><code>实战程序wordcount</code></h2><h3 id="新建WordCount项目"><a href="#新建WordCount项目" class="headerlink" title="新建WordCount项目"></a>新建WordCount项目</h3><p>File—&gt;Project，选择Map/Reduce Project，输入项目名称WordCount等。</p>
<p>在WordCount项目里新建class，名称为WordCount，代码如下:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div></pre></td><td class="code"><pre><div class="line">import java.io.IOException;</div><div class="line">import java.util.StringTokenizer;</div><div class="line"></div><div class="line">import org.apache.hadoop.conf.Configuration;</div><div class="line">import org.apache.hadoop.fs.Path;</div><div class="line">import org.apache.hadoop.io.IntWritable;</div><div class="line">import org.apache.hadoop.io.Text;</div><div class="line">import org.apache.hadoop.mapreduce.Job;</div><div class="line">import org.apache.hadoop.mapreduce.Mapper;</div><div class="line">import org.apache.hadoop.mapreduce.Reducer;</div><div class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</div><div class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</div><div class="line">import org.apache.hadoop.util.GenericOptionsParser;</div><div class="line"></div><div class="line">public class WordCount &#123;</div><div class="line"></div><div class="line">public static class TokenizerMapper extends Mapper&lt;Object, Text, Text, IntWritable&gt;&#123;</div><div class="line">　　private final static IntWritable one = new IntWritable(1);</div><div class="line">　　private Text word = new Text();</div><div class="line"></div><div class="line">　　public void map(Object key, Text value, Context context) throws IOException, InterruptedException &#123;</div><div class="line">　　　　StringTokenizer itr = new StringTokenizer(value.toString());</div><div class="line">　　　　　　while (itr.hasMoreTokens()) &#123;</div><div class="line">　　　　　　　　word.set(itr.nextToken());</div><div class="line">　　　　　　　　context.write(word, one);</div><div class="line">　　　　　　&#125;</div><div class="line">　　&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">public static class IntSumReducer extends Reducer&lt;Text,IntWritable,Text,IntWritable&gt; &#123;</div><div class="line">　　private IntWritable result = new IntWritable();</div><div class="line">　　public void reduce(Text key, Iterable&lt;IntWritable&gt; values,Context context) throws IOException, InterruptedException &#123;</div><div class="line">　　　　int sum = 0;</div><div class="line">　　　　for (IntWritable val : values) &#123;</div><div class="line">　　　　　　sum += val.get();</div><div class="line">　　　　&#125;</div><div class="line">　　　　result.set(sum);</div><div class="line">　　　　context.write(key, result);</div><div class="line">　　&#125;</div><div class="line">&#125;</div><div class="line"></div><div class="line">public static void main(String[] args) throws Exception &#123;</div><div class="line">　　Configuration conf = new Configuration();</div><div class="line">　　String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();</div><div class="line">　　if (otherArgs.length != 2) &#123;</div><div class="line">　　　　System.err.println(&quot;Usage: wordcount &lt;in&gt; &lt;out&gt;&quot;);</div><div class="line">　　　　System.exit(2);</div><div class="line">　　&#125;</div><div class="line">　　Job job = new Job(conf, &quot;word count&quot;);</div><div class="line">　　job.setJarByClass(WordCount.class);</div><div class="line">　　job.setMapperClass(TokenizerMapper.class);</div><div class="line">　　job.setCombinerClass(IntSumReducer.class);</div><div class="line">　　job.setReducerClass(IntSumReducer.class);</div><div class="line">　　job.setOutputKeyClass(Text.class);</div><div class="line">　　job.setOutputValueClass(IntWritable.class);</div><div class="line">　　FileInputFormat.addInputPath(job, new Path(otherArgs[0]));</div><div class="line">　　FileOutputFormat.setOutputPath(job, new Path(otherArgs[1]));</div><div class="line">　　System.exit(job.waitForCompletion(true) ? 0 : 1);</div><div class="line">&#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>
<h3 id="创建输入input目录"><a href="#创建输入input目录" class="headerlink" title="创建输入input目录"></a>创建输入input目录</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hadoop fs -mkdir /user</div><div class="line">hadoop fs -mkdir /user/input</div></pre></td></tr></table></figure>
<h3 id="拷贝本地README-txt到HDFS的input里"><a href="#拷贝本地README-txt到HDFS的input里" class="headerlink" title="拷贝本地README.txt到HDFS的input里"></a>拷贝本地README.txt到HDFS的input里</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hadoop fs -copyFromLocal /opt/hadoop/README.txt /user/input</div></pre></td></tr></table></figure>
<h3 id="参数配置"><a href="#参数配置" class="headerlink" title="参数配置"></a>参数配置</h3><p>点击WordCount.java，右键，点击Run As—&gt;Run Configurations，配置运行参数Arguments，即输入和输出文件夹(事先不能存在)<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">　　hdfs://localhost:9000/user/input    hdfs://localhost:9000/user/output</div></pre></td></tr></table></figure></p>
<p>然后点击运行</p>
<h3 id="查看结果"><a href="#查看结果" class="headerlink" title="查看结果"></a>查看结果</h3><p><code>hadoop fs -ls output</code>,可以看到有两个输出结果<code>_SUCCESS</code>和<code>part-r-00000</code><br>执行<code>hadoop fs -cat output/*</code></p>
<p>或者也可以展开DFS Locations，双击打开part-r00000查看结果</p>
<hr>
<p><br></p>
<h2 id="打包eclipse程序在集群上运行"><a href="#打包eclipse程序在集群上运行" class="headerlink" title="打包eclipse程序在集群上运行"></a><code>打包eclipse程序在集群上运行</code></h2><p>直接运行eclipse程序，访问localhost:8088窗口并不会显示正在运行的job，因为在eclipse上并没有配置集群环境，而是本地环境。</p>
<h3 id="打包jar"><a href="#打包jar" class="headerlink" title="打包jar"></a>打包jar</h3><p>右击工程 -&gt; export… -&gt; java -&gt; jar file -&gt; next -&gt; 填写jar包位置 -&gt; finish</p>
<h3 id="运行"><a href="#运行" class="headerlink" title="运行"></a>运行</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">hadoop jar crawler.jar MR_Crawler hdfs://localhost:9000/user/input/urls hdfs://localhost:9000/user/output</div><div class="line"># 注意用MR_Crawler是因为没有配置具体的package，如果有包要加上包名.</div></pre></td></tr></table></figure>
<hr>
<p><br></p>
<h2 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a><code>注意点</code></h2><ul>
<li>运行后台程序前, 必须格式化新安装的HDFS, 并通过创建存储目录和初始化元数据创新空的文件系统, 执行下面命令<code>hdfs namenode -format</code></li>
<li>输出文件默认不能存在</li>
</ul>
</div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2015-09-01</span><i class="fa fa-comment-o"></i><a href="/2015/09/01/hadoop-note/#comments">评论</a><i class="fa fa-tag"></i><a href="/categories/dev/" title="dev" class="tag">dev </a><a href="/tags/hadoop/" title="hadoop" class="tag">hadoop </a></div></div></div></div><div class="share"><div class="evernote"> <a href="javascript:(function(){EN_CLIP_HOST='http://www.evernote.com';try{var%20x=document.createElement('SCRIPT');x.type='text/javascript';x.src=EN_CLIP_HOST+'/public/bookmarkClipper.js?'+(new%20Date().getTime()/100000);document.getElementsByTagName('head')[0].appendChild(x);}catch(e){location.href=EN_CLIP_HOST+'/clip.action?url='+encodeURIComponent(location.href)+'&amp;title='+encodeURIComponent(document.title);}})();" ref="nofollow" target="_blank" class="fa fa-bookmark"></a></div><div class="weibo"> <a href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));" class="fa fa-weibo"></a></div><div class="twitter"> <a href="http://twitter.com/home?status=,http://www.mclspace.com/2015/09/01/hadoop-note/,坐在键盘上的猫,Mac上Hadoop的安装及使用,;" class="fa fa-twitter"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a role="navigation" href="/2015/09/16/docker-file-note/" title="创建Dockerfile" class="btn">上一篇</a></li><li class="next pagbuttons"><a role="navigation" href="/2015/08/22/docker-create-nodejs-mongodb-image/" title="[转载]用 Docker 构建 NodeJS 应用" class="btn">下一篇</a></li></ul></div><a id="comments"></a><div data-thread-key="2015/09/01/hadoop-note/" data-title="Mac上Hadoop的安装及使用" data-url="http://www.mclspace.com/2015/09/01/hadoop-note/" data-author-key="1" class="ds-thread"></div><script>var duoshuoQuery = {short_name:"coco"};
(function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
})();

</script></div></div></div></div><script src="/js/jquery.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script></body></html>